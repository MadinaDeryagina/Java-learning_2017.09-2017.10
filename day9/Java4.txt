		Шаблоны параллелизма.
	1. Самый наивный вариант.
		Есть сетевое приложение сервер, подсоеденилось 2 клиента, мы из сокетов собираемся информацию вычитывать. Самый простой вариант, это на каждого
клиент выделяем thread - такую архитектуру можно назвать thread per connection.
Полученную строчку от клиента нужно распихать по всем сокетам. Как это сделать? Как только первый сокет прочитал, он берет эту строчку из
foreach(sockets) {
		write(str)
}
	Вторая проблема, которая может быть в том, что у нас актуальность данных теряется - мы пока распихиваем строчку по потокам, мы не слушаем.
	
				_________________Server
				|
	----------->|-->s -> read ----> "...."
				|					 | |
				|					 | |
	----------->|-->s	<------------- |
				|					   |
				|					   |
	----------->|-->s	<---------------
				|
				|
				
		Как сделать нормально? Исправить предыдущую архитектуру?
		
	У нас появляется: все треды ждут, но появляется пул тредов с очередью, когда строчка появляется - мы читаем и эту строчку кидаем в threadPool, что получается с 
пулом? Он должет нашу строчку всем остальным. Делает это все параллельно, мы проблему немного решили, но увеличили количество третов.
	Как нам сделать идеальный варинт? Уменьшить количество тредов до 4? Ответ: сбросить наши треды на операционную систему.
	Тогда будет как: сокеты, но чтение мы своими функциями не делаем, нитки там будут нативные, т.е. метод read будет делать операционная система, тогда
мы как делаем? В библиотеке NIO2 есть subscriptions() - подписаться на событие, получается чтение идет нитками ОС, к нам в очередь прилетают строчки, мы их
обрабатываем бизнес-логикой и дальше делаем чтобы писалось также. NIO2 будет получать строчку и так же писать. Физических нитей в идеале делается по количеству 
ядер. Получается асинхронный ввод-вывод.

	Если хотим сделать меньше блокирующих тредов, нам надо сделать не операцию read, а операцию "есть че"(availiable), можно сделать меньше количество тредов идеале
если есть что - читам, отправляем другим клиентам.

	Клиент может залипать, если на стороне сервера сейчас ничего не считывается, для того, чтобы отслеживать, что у нас клиент залип - нам приходится делать 
отдельную нить - WatchDog(сторожевую собаку).
	Явление, когда у нас накапливаются данные в очередях называется backPression - тогда нам надо блокировать очередь - говорить, что очередь не может больше
наполнятся, и надо прекратить ее наполнять, тогда наполняется следующая очередь, которая стоит до нашей - и затем уже доходит блокировка до клиента.



